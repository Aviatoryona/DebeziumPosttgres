# Application Port
server:
  port: ${HOST_PORT:8081}
  tomcat:
    connection-timeout: 300000
    max-http-form-post-size: 100MB

# Application Name
spring:
  application:
    name: debezium-demo
  threads:
    virtual:
      enabled: true
  # Hibernate Configuration
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false # Turn off SQL logging to reduce overhead
    properties:
      hibernate:
        jdbc:
          batch_size: 50
          fetch_size: 50
        format_sql: true
        order_inserts: true
        order_updates: true
        show_sql: false
        jdbc_time_zone: UTC
        generate_statistics: false
        use_sql_comments: false

  # PostgreSQL Database Configuration
  datasource:
    url: ${DATABASE_URL:jdbc:postgresql://172.17.0.1:4432/debezium_master}
    username: ${DATABASE_USERNAME:postgres}
    password: ${DATABASE_PASSWORD:postgres}
    hikari:
      maximum-pool-size: 20 # Adjust based on an expected load
      minimum-idle: 5
      idle-timeout: 10000 # 10 seconds
      connection-timeout: 30000 # 30 seconds
      max-lifetime: 1800000 # 30 minutes

  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:2255}
    consumer:
      group-id: debezium-demo-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    streams:
      application-id: debezium-demo-app
      state-store-cache-max-size: 1000
      properties:
        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        processing.guarantee: exactly_once
        commit.interval.ms: 1000
        auto-offset-reset: none
        cache.max.bytes.buffering: 10485760 # 10 MB
        num.stream.threads: 7 # Adjust based on the number of CPU cores available
        max.poll.records: 500 # Adjust based on expected load
        max.poll.interval.ms: 300000 # 5 minutes
        max.partition.fetch.bytes: 1048576 # 1 MB
        fetch.max.wait.ms: 500 # 500 ms
        retry.backoff.ms: 100 # 100 ms
        linger.ms: 5 # 5 ms
        request.timeout.ms: 30000 # 30 seconds
        metadata.max.age.ms: 300000 # 5 minutes
        connections.max.idle.ms: 600000 # 10 minutes
        enable.auto.commit: false
        isolation.level: read_committed
        commit.on.checkpoint: true
        state.cleanup.delay.ms: 60000 # 1 minute
        state.dir: /tmp/kafka-streams # Use a local directory for state store
        state.store.cache.max.size: 1000 # Limit the size of the state store cache
        state.store.cache.expiry.ms: 600000 # 10 minutes
        state.store.cache.cleanup.interval.ms: 60000 # 1 minute
        state.store.cache.cleanup.batch.size: 100 # Batch size for cache cleanup
        state.store.cache.cleanup.max.iterations: 10 # Max iterations for cache cleanup
        state.store.cache.cleanup.min.size: 100 # Minimum size for cache cleanup
        state.store.cache.cleanup.max.size: 10000 # Maximum size for cache cleanup
        state.store.cache.cleanup.timeout.ms: 300000 # 5 minutes
        state.store.cache.cleanup.backoff.ms: 100 # 100 ms
        state.store.cache.cleanup.retry.backoff.ms: 100 # 100 ms
        state.store.cache.cleanup.max.retries: 3 # Max retries for cache cleanup
        state.store.cache.cleanup.retry.interval.ms: 1000 # 1 second
        state.store.cache.cleanup.retry.max.retries: 3 # Max retries for cache cleanup
        state.store.cache.cleanup.retry.timeout.ms: 300000 # 5 minutes
        state.store.cache.cleanup.retry.max.backoff.ms: 1000 # 1 second


# Cross-Origin Resource Sharing (CORS)
cors:
  allowed-origins: ${FRONTEND_URL:http://localhost:8081}
  allowed-methods: GET, POST, PUT, DELETE
  allowed-headers: Authorization, Content-Type
  allow-credentials: true

# Logging Configuration
logging:
  level:
    org.apache.kafka.streams: INFO
    org.apache.kafka.clients: INFO

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
  health:
    db:
      enabled: true
    diskspace:
      enabled: true
    metrics:
        enabled: true

